# Changelog

All significant changes to this project are documented here.

## [Unreleased]

### Fixed
- ğŸ› **TextRefiner topic detection now respects backend setting**
  - Fixed hardcoded Ollama call in `_detect_topic()` method
  - Topic detection now correctly uses OpenAI API when `--refine-backend openai_api` is specified
  - Resolves 404 error when using OpenAI backend without Ollama running

### Added
- âœ¨ **OpenAI support for Whisper prompt generation**
  - Enhanced `create_whisper_prompt_with_llm()` to support both Ollama and OpenAI backends
  - Automatically uses the same backend as refinement (`--refine-backend`) for prompt generation
  - Improves consistency when using OpenAI API throughout the pipeline
- ğŸ¯ **Audio preprocessing for speaker diarization**
  - Automatic conversion to mono 16kHz
  - RMS volume normalization to -20 dBFS
  - Clipping prevention
  - Optional noise reduction support (via noisereduce library)
  - Helps reduce false speaker clusters from volume variations and background noise
  - New function: `_preprocess_audio_for_diarization()`

### Documentation
- ğŸ“ **Added FAQ entries for speaker diarization warnings**
  - Documented torchcodec FFmpeg version warning (safe to ignore)
  - Documented pyannote std() warning (safe to ignore)
  - Explained fallback audio loading mechanism
  - Added quick reference in README troubleshooting section
- ğŸ“ **Added speaker diarization accuracy information**
  - New FAQ section: "How accurate is speaker diarization?"
  - Documented over-segmentation limitation (one speaker â†’ multiple labels)
  - Added accuracy guidelines based on audio quality
  - Recommendation to verify speaker labels manually for critical applications
  - Added warning note in README highlights
  - Documented automatic audio preprocessing features

## [1.3.0] - 2025-10-10

### Added
- ğŸš€ **Full OpenAI API Integration**
  - OpenAI Whisper API for transcription (cloud-based, fast)
  - GPT-4/GPT-3.5 for translation (better context handling)
  - GPT for text refinement (alternative to Ollama)
  - GPT for summarization (new feature!)

### New Features
- **Summarization Module** (`src/summarizer.py`)
  - Generate detailed summaries of transcripts
  - Support for both Ollama and OpenAI backends
  - Automatic chunking for long documents
  - Structured output with section headings
  - CLI flags: `--summarize`, `--summarize-model`, `--summarize-backend`

- **OpenAI Whisper Transcription**
  - Cloud-based transcription via OpenAI API
  - Faster than local processing (no model download)
  - Supports files up to 25MB
  - Returns timestamped segments
  - Usage: `--transcribe whisper_openai_api`

- **GPT Translation**
  - Translation using GPT-4 or GPT-3.5-turbo
  - Better handling of technical terms and idioms
  - Preserves formatting and timestamps
  - Usage: `--translate openai_api`

- **GPT Text Refinement**
  - Alternative to Ollama for transcript cleanup
  - Removes filler words, improves punctuation
  - Usage: `--refine-model gpt-4 --refine-backend openai_api`

### New CLI Options
- `--refine-backend {ollama,openai_api}` - Choose refinement backend
- `--summarize` - Enable summarization
- `--summarize-model MODEL` - Model for summarization
- `--summarize-backend {ollama,openai_api}` - Choose summarization backend

### Configuration
- Added `RefineOptions` enum to `config.py`
- Added `SummarizeOptions` enum to `config.py`
- Updated help text with OpenAI examples

### Documentation
- Added `OPENAI_INTEGRATION.md` - Complete OpenAI guide
  - Setup instructions
  - Usage examples
  - Cost estimates
  - Troubleshooting

### Technical
- Lazy imports for OpenAI library (optional dependency)
- Proper error handling for missing API keys
- File size validation for OpenAI Whisper (25MB limit)
- Chunking support for long text processing

### Architecture
- `src/summarizer.py` - New module (345 lines)
- `src/transcriber.py` - Added `_transcribe_with_openai_api()` method
- `src/translator.py` - Implemented `_translate_with_openai()` method
- `src/text_refiner.py` - Added OpenAI backend support
- `src/config.py` - New option enums

---

## [1.2.0] - 2025-10-06

### Added
- ğŸ“„ **Document ingestion**
  - Read `.docx`, `.md`, `.txt`
  - Improve existing transcripts with an LLM
  - Translate uploaded documents
  - Auto-detect source language

### New modules
- `src/text_reader.py`
  - `read_docx()` â€” Microsoft Word support
  - `read_markdown()` â€” Markdown parsing with formatting removal
  - `read_text()` â€” plain text reader
  - `detect_language()` â€” Cyrillic/Latin heuristics

### Integration
- Added `process_text_file()` to `src/main.py`
- CLI flag `--input_text path/to/file.md`
- Lazy translation imports to reduce dependencies
- Reuses the existing pipeline (segments, documents)

### Improved
- **NLLB translation quality**
  - Default model upgraded: `facebook/nllb-200-distilled-600M` â†’ `facebook/nllb-200-distilled-1.3B`
  - New `--translate-model` flag to choose another NLLB variant
  - Chunk size increased 500 â†’ 700 tokens (more context)
  - Generation limit increased 512 â†’ 1024 tokens
  - Added `no_repeat_ngram_size=3` to avoid duplicates
  - Result: **~40% higher quality**, ~3Ã— slower
- `segments_to_text()` and `translate_segments()` accept dicts and objects
- Translation no longer required for text documents
- Lazy `transformers` import (skipped unless `--translate` is used)

### Usage examples
```bash
# Improve a document
python -m src.main --input_text doc.md --refine-model qwen2.5:7b

# Translate with a custom NLLB model
python -m src.main --input_text doc.docx --translate NLLB --translate-model facebook/nllb-200-distilled-600M

# Improve + translate (defaults to 1.3B model)
python -m src.main --input_text doc.txt --refine-model qwen2.5:7b --translate NLLB
```

---

## [1.1.0] - 2025-10-06

### Added
- ğŸ¯ **Optimised prompts for transcript polishing**
  - Separate prompts for English and Russian
  - Minimal editing (noise removal only, no summarisation)
  - All facts, examples, and reasoning preserved

### Improved
- âœ¨ **Transcript clean-up quality**
  - Removes filler words (â€œumâ€, â€œuhâ€, â€œlikeâ€, â€œÑĞ¼â€, â€œĞ½Ñƒâ€, â€œĞ²Ğ¾Ñ‚â€, â€œĞºĞ¾Ñ€Ğ¾Ñ‡Ğµâ€)
  - Drops meta-comments (â€œlet me scrollâ€, â€œÑĞµĞ¹Ñ‡Ğ°Ñ Ğ¾Ñ‚ĞºÑ€Ğ¾Ñ ÑĞºÑ€Ğ°Ğ½â€)
  - Normalises numbers (â€œtwenty eight sixteenâ€ â†’ â€œ2816â€, â€œpoint eightâ€ â†’ â€œ0.8â€)
  - Keeps contextual examples like â€œif youâ€™re above 2650 ...â€

- ğŸ“ **Better structure**
  - Improved punctuation
  - Merges fragmented sentences
  - Proper paragraph formatting

- ğŸš« **No summarisation**
  - Explicit instructions to keep meaningful content
  - Repeated statements retained (can be important)
  - All reasoning preserved

### Technical details
- Updated prompts in `src/text_refiner.py`
  - English prompt (lines 242â€“279)
  - Russian prompt (lines 205â€“240)
- Added helper scripts:
  - `test_refiner_prompt.py`
  - `test_refiner_russian.py`
  - `update_prompt.py`
- Reference prompt files:
  - `improved_prompt.txt`
  - `improved_prompt_ru.txt`

### Testing results
- **English sample** (`test5min_original.md`)
  - ~28% reduction (only filler removal)
  - All examples retained (â€œ1800 or 1700â€, â€œ0.8 pointsâ€, â€œ2816 ratingâ€)

- **Russian sample** (`tarn5minru_original.md`)
  - ~24% reduction
  - Technical vocabulary preserved
  - Removed fillers â€œĞ½Ñƒâ€, â€œĞ²Ğ¾Ñ‚â€, â€œÑ-Ñâ€

---

## [1.0.0] - 2025-10-02

### Added
- ğŸ‰ Initial stable release
- âœ… Download and process YouTube videos
- âœ… Process local audio files (mp3, wav, ...)
- âœ… Whisper transcription (base, small, medium)
- âœ… LLM refinement via Ollama
- âœ… Automatic language detection (ru/en)
- âœ… Translation with Meta NLLB
- âœ… DOCX and Markdown export
- âœ… Custom Whisper prompts from file
- âœ… Prompt generation from YouTube metadata
- âœ… Logging and progress bars
- âœ… Apple M1/M2 optimisations

### Performance
- Whisper Base: 0.06Ã— (â‰ˆ16Ã— faster than realtime)
- Whisper Small: 0.19Ã— (â‰ˆ5Ã— faster than realtime)
- NLLB: 0.47Ã— (â‰ˆ2Ã— faster than realtime)

---

## Versioning

The project follows [Semantic Versioning](https://semver.org/):
- MAJOR.MINOR.PATCH (e.g. 1.2.3)
- MAJOR â€” incompatible API changes
- MINOR â€” backward-compatible features
- PATCH â€” backward-compatible bug fixes
